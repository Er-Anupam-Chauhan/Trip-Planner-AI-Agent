{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "966fd92e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting langchain==0.2.17 (from -r ../requirements.txt (line 1))\n",
      "  Using cached langchain-0.2.17-py3-none-any.whl.metadata (7.1 kB)\n",
      "Collecting langchain-community==0.2.17 (from -r ../requirements.txt (line 2))\n",
      "  Using cached langchain_community-0.2.17-py3-none-any.whl.metadata (2.7 kB)\n",
      "Collecting langchain-experimental==0.0.61 (from -r ../requirements.txt (line 3))\n",
      "  Using cached langchain_experimental-0.0.61-py3-none-any.whl.metadata (1.5 kB)\n",
      "Requirement already satisfied: langchain-groq in c:\\users\\admin\\anaconda3\\lib\\site-packages (from -r ../requirements.txt (line 4)) (0.3.8)\n",
      "Collecting langchain-openai==0.1.9 (from -r ../requirements.txt (line 5))\n",
      "  Using cached langchain_openai-0.1.9-py3-none-any.whl.metadata (2.5 kB)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: Ignoring invalid distribution ~rotobuf (c:\\Users\\Admin\\anaconda3\\Lib\\site-packages)\n",
      "ERROR: Could not find a version that satisfies the requirement langchain-tavily==0.0.4 (from versions: 0.1.5, 0.1.6, 0.2.0, 0.2.1, 0.2.2, 0.2.3, 0.2.4, 0.2.5, 0.2.6, 0.2.7, 0.2.8, 0.2.9, 0.2.10, 0.2.11)\n",
      "\n",
      "[notice] A new release of pip is available: 25.1.1 -> 25.2\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for langchain-tavily==0.0.4\n"
     ]
    }
   ],
   "source": [
    "!pip install -r ../requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "345cb5db",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Disabling PyTorch because PyTorch >= 2.1 is required but found 2.0.1\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "from dotenv import load_dotenv\n",
    "load_dotenv()\n",
    "from langchain_groq import ChatGroq\n",
    "llm=ChatGroq(model=\"deepseek-r1-distill-llama-70b\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "80e76763",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "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\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "print(os.getenv(\"GROQ_API_KEY\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87f48f05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AIMessage(content=\"<think>\\n\\n</think>\\n\\nHello! I'm just a virtual assistant, so I don't have feelings, but I'm here and ready to help you with whatever you need. How are you doing? ðŸ˜Š\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 42, 'prompt_tokens': 9, 'total_tokens': 51, 'completion_time': 0.219227534, 'prompt_time': 0.010486787, 'queue_time': 0.044661613, 'total_time': 0.229714321}, 'model_name': 'deepseek-r1-distill-llama-70b', 'system_fingerprint': 'fp_1bbe7845ec', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--e045de46-7d45-4de9-86cb-1d7fff423b78-0', usage_metadata={'input_tokens': 9, 'output_tokens': 42, 'total_tokens': 51})"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "llm.invoke(\"Hello, how are you?\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7453ac65",
   "metadata": {},
   "outputs": [],
   "source": [
    "GROQ_API_KEY=\"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\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "eab0f231",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<think>\n",
      "Okay, I need to write a haiku about fast AI. Let me think about what that means. A haiku is a three-line poem with a 5-7-5 syllable structure. So each line has to fit that.\n",
      "\n",
      "First, I should consider the theme: fast AI. Maybe something about speed, processing, learning. The first line could be about the AI moving quickly. Maybe \"Whirring circuits dance\" â€“ that gives a sense of movement and speed.\n",
      "\n",
      "The second line needs seven syllables. I want to show the AI's capability. \"Processing the world\" is four syllables. Maybe add something about learning. \"Invisible mind learns fast\" â€“ that's seven syllables and shows the AI's learning speed.\n",
      "\n",
      "The third line, five syllables again. I want to convey the future aspect. \"Future unfolds now\" â€“ that captures the idea of rapid progress bringing the future sooner.\n",
      "\n",
      "Let me check the syllables: 5,7,5. Yep, that works. The imagery is about the AI's speed and impact on the future. I think that covers the theme effectively.\n",
      "</think>\n",
      "\n",
      "Whirring circuits dance,  \n",
      "Invisible mind learns fast,  \n",
      "Future unfolds now.\n"
     ]
    }
   ],
   "source": [
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "\n",
    "load_dotenv()   # if you're using a .env file\n",
    "\n",
    "llm = ChatGroq(\n",
    "    model=\"deepseek-r1-distill-llama-70b\",  # or \"mixtral-8x7b\" etc.\n",
    "    temperature=0.7\n",
    ")\n",
    "\n",
    "response = llm.invoke(\"Write a short haiku about fast AI.\")\n",
    "print(response.content)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6bf6b28e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "StructuredTool(name='multiply', description='Multiply two integers.\\n\\nArgs:\\n    a (int): The first integer.\\n    b (int): The second integer.\\n\\nReturns:\\n    int: The product of a and b.', args_schema=<class 'langchain_core.utils.pydantic.multiply'>, func=<function multiply at 0x000002D986F97CE0>)"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain.tools import tool\n",
    "@tool\n",
    "def multiply(a: int, b: int) -> int:\n",
    "    \"\"\"\n",
    "    Multiply two integers.\n",
    "\n",
    "    Args:\n",
    "        a (int): The first integer.\n",
    "        b (int): The second integer.\n",
    "\n",
    "    Returns:\n",
    "        int: The product of a and b.\n",
    "    \"\"\"\n",
    "    return a * b\n",
    "multiply"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "881bf8e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.tools import StructuredTool\n",
    "from pydantic import BaseModel\n",
    "class WeatherInput(BaseModel):\n",
    "    city: str\n",
    "\n",
    "def get_weather(city: str) -> str:\n",
    "    \"\"\"\n",
    "    Get the weather for a given city.\n",
    "\n",
    "    Args:\n",
    "        city (str): The name of the city.\n",
    "\n",
    "    Returns:\n",
    "        str: A string describing the weather in the city.\n",
    "    \"\"\"\n",
    "    return f\"The weather in {city} is sunny.\"\n",
    "weather_tool = StructuredTool.from_function(\n",
    "    func=get_weather,\n",
    "    name=\"get_weather\",\n",
    "    description=\"Fetches real-time weather data for a city\",\n",
    "    args_schema=WeatherInput,  \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "70faf81e",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Field' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWeatherInput\u001b[39;00m(BaseModel):\n\u001b[0;32m      2\u001b[0m     city: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     units: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric or imperial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m, in \u001b[0;36mWeatherInput\u001b[1;34m()\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mclass\u001b[39;00m \u001b[38;5;21;01mWeatherInput\u001b[39;00m(BaseModel):\n\u001b[1;32m----> 2\u001b[0m     city: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;241m.\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCity name\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m      3\u001b[0m     units: \u001b[38;5;28mstr\u001b[39m \u001b[38;5;241m=\u001b[39m Field(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric\u001b[39m\u001b[38;5;124m\"\u001b[39m, description\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetric or imperial\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Field' is not defined"
     ]
    }
   ],
   "source": [
    "class WeatherInput(BaseModel):\n",
    "    city: str = Field(..., description=\"City name\")\n",
    "    units: str = Field(\"metric\", description=\"metric or imperial\")\n",
    "\n",
    "class GetWeatherTool(StructuredTool):\n",
    "    name: ClassVar[str] = \"get_weather\"           \n",
    "    description: ClassVar[str] = (\n",
    "        \"Fetches weather data for a city\"\n",
    "    )\n",
    "    args_schema: ClassVar[Type[BaseModel]] = WeatherInput\n",
    "\n",
    "    def _run(self, city: str, units: str = \"metric\") -> str:\n",
    "        return get_weather(city, units)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "28771bee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
